{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN2zqFW0e6GyIVKkFFwFyE+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khaerensml6/uva_exercise/blob/main/uva_diffusion_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -n https://github.com/khaerensml6/uva_exercise.git --depth 1\n",
        "!cd uva_exercise; git checkout HEAD clip_client.py\n",
        "!cd uva_exercise; mv clip_client.py ..\n"
      ],
      "metadata": {
        "id": "yyMFmgz5N11u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data exploration: LAION-5B\n",
        "\n"
      ],
      "metadata": {
        "id": "s1Gig-3CIhRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "p4MrsXKwIcoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some helper Functions\n"
      ],
      "metadata": {
        "id": "QVihumtICB9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def crop_image(original_image, size=512):\n",
        "\n",
        "    if original_image.size[0] < original_image.size[1]:\n",
        "        resized_image = original_image.resize(\n",
        "            (size, int(size * original_image.size[1] / original_image.size[0])))\n",
        "    else:\n",
        "        resized_image = original_image.resize(\n",
        "            (int(size * original_image.size[0] / original_image.size[1]), size))\n",
        "\n",
        "    w, h = resized_image.size\n",
        "    left = (w - size) // 2\n",
        "    top = (h - size) // 2\n",
        "    right = (w + size) // 2\n",
        "    bottom = (h + size) // 2\n",
        "\n",
        "    cropped_image = resized_image.crop((left, top, right, bottom))\n",
        "\n",
        "    return cropped_image\n",
        "\n",
        "def image_grid(imgs, size):\n",
        "\n",
        "    if len(imgs) > 4:\n",
        "      rows=math.ceil(len(imgs)/4)\n",
        "      cols=4\n",
        "    else:\n",
        "      rows = 1\n",
        "      cols = len(imgs)\n",
        "\n",
        "    w, h = size, size\n",
        "    imgs = [crop_image(img, w) for img in imgs]\n",
        "\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid"
      ],
      "metadata": {
        "id": "Lk-FtP63NV3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query Parameters"
      ],
      "metadata": {
        "id": "9uGgeXRlCHJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_images = 20\n",
        "aesthetic_score = 9 # number from 1-10: \"prettiness\" of the images to retrieve\n",
        "aesthetic_weight = 0.5"
      ],
      "metadata": {
        "id": "Z3zgau8qJkDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from clip_client import ClipClient, Modality\n",
        "\n",
        "laion_client = ClipClient(\n",
        "            url=\"https://knn.laion.ai/knn-service\",\n",
        "            indice_name=\"laion5B-L-14\",\n",
        "            num_images=number_of_images,\n",
        "            aesthetic_score=aesthetic_score,\n",
        "            aesthetic_weight=aesthetic_weight,\n",
        "            modality=Modality.IMAGE,\n",
        "        )"
      ],
      "metadata": {
        "id": "nnI_lHYwIyep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Querying LAION with text"
      ],
      "metadata": {
        "id": "aZrQIcO0vBDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_string = \"cat with hat\""
      ],
      "metadata": {
        "id": "s8xcuuequi-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_images = laion_client.query(text=query_string)\n",
        "print(f\"Found {len(retrieved_images)} image urls!\")"
      ],
      "metadata": {
        "id": "i3Hw2KXXKhFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "import io\n",
        "\n",
        "images = []\n",
        "for i, response in enumerate(retrieved_images):\n",
        "  image_url = response[\"url\"]\n",
        "  try:\n",
        "\n",
        "    dataBytesIO = io.BytesIO(requests.get(image_url, stream=True).content)\n",
        "    image = Image.open(dataBytesIO)\n",
        "    images.append(image)\n",
        "\n",
        "    print(f\"Found image {i} with caption: \\n\\t \\\"{response['caption']}\\\"\\n\")\n",
        "  except Exception as e:\n",
        "    print(f\"encountered a dead link for image {i}!\\n\")"
      ],
      "metadata": {
        "id": "FK6C9jxnK4rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qL2Y4hXFjVjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_grid(images)"
      ],
      "metadata": {
        "id": "zgHbDNoWLmTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Querying LAION with an image"
      ],
      "metadata": {
        "id": "MzOI7l7Lu7gX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# download a sample query image:\n",
        "# or comment out the line below and upload your own image under the name \"query_image.png\"\n",
        "!curl \"https://media.istockphoto.com/photos/paghetti-with-tomato-sauce-capers-and-olives-picture-id696166506?k=6&amp;m=696166506&amp;s=612x612&amp;w=0&amp;h=-hV4BZr3ekV0tJQ2x-vg_sSQKXm7qaqzDgl8fDEp9NE=\" > query_image.png\n",
        "query_image = Image.open(\"query_image.png\")\n",
        "query_image\n"
      ],
      "metadata": {
        "id": "Dm8N64VpipNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "laion_client.num_images=30\n",
        "retrieved_images = laion_client.query(image=\"query_image.png\")\n",
        "print(f\"Found {len(retrieved_images)} images\")\n"
      ],
      "metadata": {
        "id": "Le0QNm_HmxjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "for i, response in enumerate(retrieved_images):\n",
        "  image_url = response[\"url\"]\n",
        "  try:\n",
        "\n",
        "    dataBytesIO = io.BytesIO(requests.get(image_url, stream=True).content)\n",
        "    image = Image.open(dataBytesIO)\n",
        "    images.append(image)\n",
        "\n",
        "    print(f\"Found image {i} with caption: \\n\\t \\\"{response['caption']}\\\"\\n\")\n",
        "  except Exception as e:\n",
        "    print(f\"encountered a dead link for image {i}!\\n\")"
      ],
      "metadata": {
        "id": "aXl3MnWcoGyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_grid(images)"
      ],
      "metadata": {
        "id": "wjZhbgBDonvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating images using StableDiffusion\n",
        "\n",
        "First, make sure we're using a GPU:\n",
        "\n"
      ],
      "metadata": {
        "id": "UyyXflzxCUyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "ds4IJqVRCUXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If not, you can change the runtime in the upper right corner"
      ],
      "metadata": {
        "id": "WB4Wei7FCrDh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing dependencies:"
      ],
      "metadata": {
        "id": "k9HOB9P-C_Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet --upgrade diffusers transformers accelerate mediapy"
      ],
      "metadata": {
        "id": "tRKO6kWGC7Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import AutoPipelineForText2Image\n",
        "import torch\n",
        "\n",
        "pipe = AutoPipelineForText2Image.from_pretrained(\n",
        "    \"stabilityai/sdxl-turbo\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    variant=\"fp16\",\n",
        "    )\n",
        "\n",
        "pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "u_pBhM7zCpgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Analog photograph of a cat with a hat\"\n",
        "\n",
        "num_inference_steps = 4\n",
        "number_of_images = 4\n",
        "\n",
        "images = pipe(\n",
        "    prompt = [prompt] * number_of_images,\n",
        "    guidance_scale = 0.5,\n",
        "    num_inference_steps = num_inference_steps,\n",
        "    ).images\n",
        "\n",
        "\n",
        "image_grid(images, 512)"
      ],
      "metadata": {
        "id": "QP-noX0_DP39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using controlnet"
      ],
      "metadata": {
        "id": "cPP8mxtaI3Eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q opencv-contrib-python\n",
        "!pip install -q controlnet_aux\n",
        "!pip install xformers"
      ],
      "metadata": {
        "id": "GDgBKS_xI2ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some helper functions"
      ],
      "metadata": {
        "id": "TQprMdZUNZXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "def create_depth_img(input_image):\n",
        "    \"\"\"Creates a depth image from the input image.\"\"\"\n",
        "    depth_estimator = pipeline('depth-estimation')\n",
        "\n",
        "    image = depth_estimator(input_image)['depth']\n",
        "    image = np.array(image)\n",
        "    image = image[:, :, None]\n",
        "    image = np.concatenate([image, image, image], axis=2)\n",
        "    image = Image.fromarray(image)\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "B3YdFNIFL3wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the conditioning image"
      ],
      "metadata": {
        "id": "_X7Jpo4sNcVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionControlNetPipeline\n",
        "from diffusers.utils import load_image\n",
        "\n",
        "\n",
        "image = load_image(\n",
        "    \"https://hf.co/datasets/huggingface/documentation-images/resolve/main/diffusers/input_image_vermeer.png\"\n",
        ")\n",
        "image"
      ],
      "metadata": {
        "id": "X3RHihkWJK-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1_Uh1hPiNn2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "depth_image = create_depth_img(image)\n",
        "depth_image"
      ],
      "metadata": {
        "id": "tHKWlxIfMNbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
        "import torch\n",
        "from diffusers import UniPCMultistepScheduler\n",
        "\n",
        "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-depth\", torch_dtype=torch.float16)\n",
        "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\", controlnet=controlnet, torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4A3bWEMBJQQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some optimization settings"
      ],
      "metadata": {
        "id": "slqQtsOlKJVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.enable_model_cpu_offload()\n"
      ],
      "metadata": {
        "id": "JCTiGbuyKI9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [f\"a painting of a women by {painter}\" for painter in [\"Vincent Van Gogh\", \"Piet Mondriaan\", \"Pieter-paul Rubens\", \"Karel Appel\"] ]\n",
        "\n",
        "\n",
        "print(len(prompts))\n",
        "\n",
        "output = pipe(\n",
        "    prompts,\n",
        "    depth_image,\n",
        "    negative_prompt=[\"monochrome, lowres, bad anatomy, worst quality, low quality\"] * len(prompts),\n",
        "    num_inference_steps=20,\n",
        ")\n",
        "\n",
        "\n",
        "image_grid(output.images, 512)\n"
      ],
      "metadata": {
        "id": "aSj2TjzzJcRx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}